# Vector DB 통합 PLAN

## Problem 1-Pager
- **배경**: StockTeacher는 뉴스 요약 파이프라인과 웹/챗 인터페이스를 제공하지만, 사용자의 후속 질문은 단순 규칙 기반 응답만 지원한다.
- **문제**: 관련 리포트 탐색·설명 능력이 떨어져 챗 경험이 제한적이며, 비슷한 이슈 추천 같은 재사용 가치도 낮다.
- **목표**: Vector DB를 도입해 리포트/기사 임베딩 기반 검색을 제공하고, 챗봇 답변 품질을 향상한다.
- **비목표**: 이번 단계에서 Celery 분석 파이프라인(collect/analyze) 내 프롬프트 구조를 전면 교체하거나, Slack 봇을 즉시 구현하지 않는다.
- **제약**: 최소 5분 내 응답, LLM 비용 상한 준수, 기존 Postgres 스키마와 JobRun 추적 유지, 테스트 추가.

## 대안 비교
| 옵션 | 설명 | 장점 | 단점 |
| --- | --- | --- | --- |
| Option B | 분석 단계에서 RAG로 대체 기사 검색 후 요약 프롬프트 보강 | 토큰 효율↑, insight 품질 향상 | Celery 파이프라인 복잡도 증가, 실패 시 재시도 경로 위험 |
| Option C | 챗봇/웹에서 질문 임베딩 → Vector 검색 → 답변 생성 | 사용자 즉시 체감, API 레이어만 수정, Slack·추천 기능으로 확장 용이 | LLM 기반 응답 로직 신규 개발, Vector 인프라 운용 필요 |

**결론**: Option C를 1순위로 진행한다. 대화 품질 개선 효과가 크고, 분석 파이프라인을 건드리지 않아 리스크가 낮다. 구축한 인덱스는 이후 Slack 및 추천 기능에 재활용할 수 있다.

## 실행 단계
1. **임베딩 설계**  
   - ProcessedInsight 및 원문 기사의 key 필드를 임베딩 → Vector DB 업서트(예: Qdrant/Weaviate)  
   - 업데이트 파이프라인은 materializer 완료 이후 후속 처리로 연결
2. **검색 API 추가**  
   - `api/routes.py` 챗 엔드포인트에 Vector 검색 호출 추가  
   - RAG 컨텍스트를 LLM 응답/템플릿에 주입, guardrail 로깅
3. **웹/Slack 연동 준비**  
   - 웹 챗 UI는 추가 컨텍스트를 표시하고, Slack 봇은 동일 API를 호출하도록 향후 확장  
   - 관련 보고서 추천을 위한 REST 엔드포인트 초안 구상

## 검증 & 모니터링
- E2E 테스트: Vector 검색 → RAG 답변 경로에서 예상 응답(성공/페일) 검증
- 관찰성: 검색 질의, 매칭된 insight ID, LLM 토큰/비용 로그 추가
- 롤아웃: 베타 사용자 대화 로그 점검 후 Slack/추천 기능 순차 적용

